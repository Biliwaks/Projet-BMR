{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of mobile robotics project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import time              #127 frames in 18 sec : approximately 7 frames per second for vision\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import serial\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from math import *\n",
    "import numpy.ma as ma\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# Adding the src folder in the current directory as it contains the script\n",
    "# with the Thymio class\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'image_project'))\n",
    "\n",
    "from Thymio import Thymio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = Thymio.serial(port=\"/dev/cu.usbmodem14101\", refreshing_rate=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_var(\"motor.left.target\", 0)\n",
    "th.set_var(\"motor.right.target\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENT:\n",
    "* [1. Vision](#1)\n",
    "    * [1.1. Intro](#1_1)\n",
    "    * [1.2. Circle Detection](#1_2)\n",
    "    * [1.3. Corner Detection](#1_3)\n",
    "* [2. Path planning and Global navigation](#2)\n",
    "* [3. Local Avoidance](#3)\n",
    "    * [3.1. Odometry](#3_1)\n",
    "    * [3.2. Sensors](#3_2)\n",
    "    * [3.3. Algorithm](#3_3)\n",
    "    * [3.4 Limitations](#3_4)\n",
    "* [4. Kalman filtering](#4)\n",
    "    * [4.1. Translation](#4_1)\n",
    "    * [4.1. Rotation](#4_1)\n",
    "* [5. Main](#5)\n",
    "* [6. Limitation of the system](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vision <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Intro <a class=\"anchor\" id=\"1_1\"></a>\n",
    "We start with the vision part where we use OpenCV and a camera to detect:\n",
    "- Corners of obstacles \n",
    "- Initial position of the center of the robot (Red circle)\n",
    "- Orientation of the robot with a circle placed on the robot next to its center (Blue circle)\n",
    "- The final desired position of the robot (Green circle)\n",
    "\n",
    "The corners of the obstacles are obtained with an implementation of a Harris Corner Detector. \n",
    "<a href='https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html'>\n",
    "Source for the Harris Corner Detector </a> \n",
    "\n",
    "The colored circles are simply obtained with three different color filters (Red, Green and Blue). We then use a median filter to reduce noise and have uniform circles. Their centroids are finally calculated and represent the different coordinates we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <b>Map with random initialisation of robot position and goal</b>\n",
    "<img src = \"image_project/FinalMap_ex.jpg\" alt=\"Drawing\" width = 500/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigger green circle represents the goal to be reached by the robot, the red circle represents the center of the robot and the blue circle represents the nose of the robot and can be used to find its orientaiton. We see that in the above situation, the robot starts facing the top left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vision():\n",
    "    \"\"\" This function localizes every circle's centroid and every obstacle's corner \"\"\"\n",
    "\n",
    "    # Initialise the array that will contain several circle centroids to calculate the error between them.\n",
    "    red_centroid_series = np.empty((0,2), float)\n",
    "    green_centroid_series = np.empty((0,2), float)\n",
    "    blue_centroid_series = np.empty((0,2), float)\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        ###########################################################################################\n",
    "        # CORNERS DETECTION\n",
    "        ###########################################################################################\n",
    "        \n",
    "        Map = frame.copy()\n",
    "        \n",
    "        # Harris Corner Detector\n",
    "        gray = cv2.cvtColor(Map, cv2.COLOR_BGR2GRAY)\n",
    "        gray = np.float32(gray)\n",
    "        dst = cv2.cornerHarris(gray,5,3,0.04)\n",
    "        ret, dst = cv2.threshold(dst,0.1*dst.max(),255,0)\n",
    "        dst = np.uint8(dst)\n",
    "        ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "        corners  = cv2.cornerSubPix(gray,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "        # Here is a way to resolve a problem that happen when an image is mostly white and corners are very clear. \n",
    "        # In this case, Harris Detector will wrongly take into account the image corners (0,0) (1280,0) (0,960) (1280,960).\n",
    "        # So a wrong centroid (1280/2,960/2) will be added and has to be deleted.\n",
    "        for c in range(len(corners)):\n",
    "            if (corners[c,0] < 645) & (corners[c,0] > 635) & (corners[c,1] < 485) & (corners[c,1] > 475):\n",
    "                corners = np.delete(corners,c,axis=0)\n",
    "                break\n",
    "\n",
    "        # Show all of the frame corners found and circle them.\n",
    "        for c in corners:\n",
    "            cv2.circle(Map,((int)(c[0]), (int)(c[1])),20,(0,0,255), 2)\n",
    "\n",
    "        # We order the corners in the same configuration each time because we know how the map looks like.\n",
    "        # In this manner, the global navigation will know which corner is which. \n",
    "        ordered_corners = np.array([[0,0] for i in range(10)])\n",
    "\n",
    "        # We have four different obstacles, so we will divide the corners in four different arrays.\n",
    "        obst1 = np.empty((0,2), float)\n",
    "        obst2 = np.empty((0,2), float)\n",
    "        obst3 = np.empty((0,2), float)\n",
    "        obst4 = np.empty((0,2), float)\n",
    "\n",
    "        while(True):\n",
    "\n",
    "            # We associate the corners to their obstacles by dividing the map in subspaces.\n",
    "            for c in corners :\n",
    "                if (c[0] >= 750) & (c[0] <= 1050) :\n",
    "                    obst1 = np.append(obst1,  np.array([c]), axis=0)\n",
    "                elif (c[0] <= 200) & (c[0] >= 0):\n",
    "                    obst2 = np.append(obst2, np.array([c]), axis=0)\n",
    "                elif (c[0] < 600) & (c[0] > 350) & (c[1] <= 960/2) & (c[1] >= 0):\n",
    "                    obst3 = np.append(obst3, np.array([c]), axis=0)\n",
    "                elif (c[0] < 600) & (c[0] > 350) & (c[1] > 960/2) & (c[1] <= 960):\n",
    "                    obst4 = np.append(obst4, np.array([c]), axis=0)\n",
    "\n",
    "            # Each obstacles should have four corners    \n",
    "            if (len(obst1) != 4) | (len(obst2) != 4) | (len(obst3) != 4) | (len(obst4) != 4):\n",
    "                good_corners = False\n",
    "                break\n",
    "\n",
    "            # We then localize the corners of each obstacles by using the sum of the coordinates \n",
    "            idx_max = np.argmax(np.sum(obst1, axis=1))\n",
    "            idx_min = np.argmin(np.sum(obst1, axis=1))\n",
    "            ordered_corners[8] = obst1[idx_max]\n",
    "            ordered_corners[6] = obst1[idx_min]\n",
    "            obst1 = np.delete(obst1,idx_max,axis=0) \n",
    "            obst1 = np.delete(obst1,idx_min,axis=0)\n",
    "            ordered_corners[9] = obst1[np.argmax(np.sum(obst1, axis=1))]\n",
    "            ordered_corners[7] = obst1[np.argmin(np.sum(obst1, axis=1))]\n",
    "\n",
    "            idx_max = np.argmax(np.sum(obst2, axis=1))\n",
    "            idx_min = np.argmin(np.sum(obst2, axis=1))\n",
    "            ordered_corners[1] = obst2[idx_max]\n",
    "            obst2 = np.delete(obst2,idx_max,axis=0)\n",
    "            obst2 = np.delete(obst2,idx_min,axis=0)\n",
    "            ordered_corners[0] = obst2[np.argmin(np.sum(obst2, axis=1))]\n",
    "\n",
    "            idx_max = np.argmax(np.sum(obst3, axis=1))\n",
    "            idx_min = np.argmin(np.sum(obst3, axis=1))\n",
    "            ordered_corners[3] = obst3[idx_max]\n",
    "            obst3 = np.delete(obst3,idx_max,axis=0)\n",
    "            obst3 = np.delete(obst3,idx_min,axis=0)\n",
    "            ordered_corners[2] = obst3[np.argmax(np.sum(obst3, axis=1))]\n",
    "\n",
    "            idx_max = np.argmax(np.sum(obst4, axis=1))\n",
    "            idx_min = np.argmin(np.sum(obst4, axis=1))\n",
    "            ordered_corners[4] = obst4[idx_min]\n",
    "            obst4 = np.delete(obst4,idx_max,axis=0)\n",
    "            obst4 = np.delete(obst4,idx_min,axis=0)\n",
    "            ordered_corners[5] = obst4[np.argmin(np.sum(obst4, axis=1))]\n",
    "\n",
    "            # Check if corners are well ordered. This loop will print the number of the corner directly on it.\n",
    "            n = 0\n",
    "            for c in ordered_corners:\n",
    "                cv2.putText(Map, str(n), ((int)(c[0]), (int)(c[1])), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                n += 1\n",
    "\n",
    "            good_corners = True\n",
    "            break\n",
    "\n",
    "\n",
    "        #######################################################################################\n",
    "        # COLORED CIRCLE DETECTION\n",
    "        #######################################################################################\n",
    "        \n",
    "        # HSV is better to manage colors exposed to different luminosity for example \n",
    "        hsv_frame  = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # For each colored circle, we create a filter in the adequate range.\n",
    "        # We then filter the frame and keep only the colors in the range.\n",
    "        # We apply a median filter to reduce the noise and get uniform circles (whitout black holes in them)\n",
    "        # Finally, we find the centroids by averaging the colored pixel in range.\n",
    "\n",
    "        #GREEN \n",
    "        low_green  = np.array([50, 60, 60])            # Range of green we want to filter\n",
    "        high_green = np.array([70, 255, 255])\n",
    "        green_mask = cv2.inRange(hsv_frame, low_green, high_green) # Mask only containing green in range\n",
    "        median_g   = cv2.medianBlur(green_mask, 5)                 # Median filtered mask\n",
    "        green      = cv2.bitwise_and(frame, frame, mask=median_g)  \n",
    "\n",
    "        if median_g.any() == True:   # Check if we have at least one pixel in the green range we want\n",
    "            green_coord    = cv2.findNonZero(median_g)                   #get all non zero values\n",
    "            green_centroid = np.mean(green_coord, axis = 0)\n",
    "            cv2.circle(Map,((int)(green_centroid[0][0]),(int)(green_centroid[0][1])),20,(255,0,0), 2)\n",
    "\n",
    "        #RED \n",
    "        low_red    = np.array([0, 75, 75])\n",
    "        high_red   = np.array([10, 255, 255])\n",
    "        red_mask1  = cv2.inRange(hsv_frame, low_red, high_red)\n",
    "\n",
    "        # Range for upper range\n",
    "        low_red   = np.array([170,75,75])\n",
    "        high_red  = np.array([180,255,255])\n",
    "        red_mask2 = cv2.inRange(hsv_frame,low_red,high_red)\n",
    "\n",
    "        # Generating the final mask to detect red color\n",
    "        red_mask = red_mask1 + red_mask2\n",
    "\n",
    "        median_r = cv2.medianBlur(red_mask, 5)\n",
    "        red      = cv2.bitwise_and(frame, frame, mask=median_r)\n",
    "\n",
    "\n",
    "        if median_r.any() == True:\n",
    "            red_coord    = cv2.findNonZero(median_r)                   #get all non zero values\n",
    "            red_centroid = np.mean(red_coord, axis = 0)\n",
    "            cv2.circle(Map,((int)(red_centroid[0][0]),(int)(red_centroid[0][1])),20,(255,0,0), 2)\n",
    "            \n",
    "\n",
    "\n",
    "        #BLUE\n",
    "        low_blue  = np.array([110,75,75])\n",
    "        high_blue = np.array([130,255,255])\n",
    "        blue_mask = cv2.inRange(hsv_frame, low_blue, high_blue)\n",
    "        median_b  = cv2.medianBlur(blue_mask, 5)\n",
    "        blue      = cv2.bitwise_and(frame, frame, mask=median_b)\n",
    "\n",
    "\n",
    "        if median_b.any() == True:\n",
    "            blue_coord    = cv2.findNonZero(median_b)                   #get all non zero values\n",
    "            blue_centroid = np.mean(blue_coord, axis = 0)\n",
    "            cv2.circle(Map,((int)(blue_centroid[0][0]),(int)(blue_centroid[0][1])),20,(255,0,0), 2)\n",
    "\n",
    "\n",
    "        #Add red green and blue\n",
    "        red_green = cv2.add(red,green)\n",
    "        rgb = cv2.add(red_green,blue)\n",
    "\n",
    "\n",
    "        err_red   = 0\n",
    "        err_green = 0\n",
    "        err_blue  = 0\n",
    "\n",
    "        err_max = 10\n",
    "        min_centroid_nb = 10\n",
    "\n",
    "        # This part verify that the circles are stable. It checks that we have several calculated centroids \n",
    "        # in a row in a small range. It avoids wrong calculated centroids because of noise.\n",
    "        if (good_corners == True) & ('red_centroid' in locals()) & ('green_centroid' in locals()) & ('blue_centroid' in locals()):\n",
    "            red_centroid_series = np.append(red_centroid_series, red_centroid, axis=0)\n",
    "            green_centroid_series = np.append(green_centroid_series, green_centroid, axis=0)\n",
    "            blue_centroid_series = np.append(blue_centroid_series, blue_centroid, axis=0)\n",
    "\n",
    "            lr = len(red_centroid_series)\n",
    "            lg = len(green_centroid_series)\n",
    "            lb = len(blue_centroid_series)\n",
    "\n",
    "            # Calculate distance between the different calculated centroids (the error).\n",
    "            for i in range(lr-1):\n",
    "                for j in range(i,lr-1):\n",
    "                    err_red = max(err_red,np.sqrt(np.sum(np.square(red_centroid_series[i,:]-red_centroid_series[j+1,:]))))\n",
    "\n",
    "            for i in range(lg-1):\n",
    "                for j in range(i,lg-1):\n",
    "                    err_green = max(err_green,np.sqrt(np.sum(np.square(green_centroid_series[i,:]-green_centroid_series[j+1,:]))))\n",
    "\n",
    "            for i in range(lb-1):\n",
    "                for j in range(i,lb-1):\n",
    "                    err_blue = max(err_blue,np.sqrt(np.sum(np.square(blue_centroid_series[i,:]-blue_centroid_series[j+1,:]))))\n",
    "\n",
    "            # If the error is to big, we empty the arrays and have to count several centroids again.\n",
    "            if (err_red > err_max) or (err_green > err_max) or (err_blue > err_max):\n",
    "                red_centroid_series   = np.empty((0,2), float)\n",
    "                green_centroid_series = np.empty((0,2), float)\n",
    "                blue_centroid_series  = np.empty((0,2), float)\n",
    "\n",
    "            # If we have many centroids calculated with distance between them in a small range, we can use the data.\n",
    "            if (err_red < err_max) and (err_green < err_max) and (err_blue < err_max) and (lb > min_centroid_nb) and (lg > min_centroid_nb) and (lr > min_centroid_nb):\n",
    "\n",
    "                # Layout is the array containing the center of the robot, its goal and the coordinates of the corners. \n",
    "                layout = np.empty((0,2), float)\n",
    "\n",
    "                layout = np.append(layout, [np.mean(red_centroid_series,axis=0)], axis=0)\n",
    "                layout = np.append(layout, ordered_corners, axis=0)\n",
    "                layout = np.append(layout, [np.mean(green_centroid_series,axis=0)], axis=0)\n",
    "\n",
    "                layout = layout.tolist()     \n",
    "                \n",
    "                # Blue_mean is the second point on the robot used to define robot's orientation.\n",
    "                blue_mean = np.array([np.mean(blue_centroid_series,axis=0)])\n",
    "                \n",
    "                return layout,blue_mean\n",
    "\n",
    "        ###########################################################################################\n",
    "\n",
    "        #Show \n",
    "        #cv2.imshow(\"rgb\", rgb)              # Possibility to see superposed filtered circles\n",
    "        \n",
    "        cv2.putText(Map, 'Map Scan', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow(\"Map\", Map)\n",
    "\n",
    "        #Waits for a user input to quit the application\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_red_blue() :\n",
    "    \"\"\" Get red and blue circle centroids just like the function above \"\"\"\n",
    "    \n",
    "    while(True):\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        hsv_frame  = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        #RED \n",
    "        low_red    = np.array([0, 75, 75])\n",
    "        high_red   = np.array([10, 255, 255])\n",
    "        red_mask1  = cv2.inRange(hsv_frame, low_red, high_red)\n",
    "\n",
    "        # Range for upper range\n",
    "        low_red = np.array([170,75,75])\n",
    "        high_red = np.array([180,255,255])\n",
    "        red_mask2 = cv2.inRange(hsv_frame,low_red,high_red)\n",
    "\n",
    "        # Generating the final mask to detect red color\n",
    "        red_mask = red_mask1 + red_mask2\n",
    "\n",
    "        median_r = cv2.medianBlur(red_mask, 5)\n",
    "        red     = cv2.bitwise_and(frame, frame, mask=median_r)\n",
    "\n",
    "\n",
    "        if median_r.any() == True:\n",
    "            red_coord    = cv2.findNonZero(median_r)                   #get all non zero values\n",
    "            red_centroid = np.mean(red_coord, axis = 0)\n",
    "            cv2.circle(red,((int)(red_centroid[0][0]),(int)(red_centroid[0][1])),20,(255,255,255), 2)\n",
    "\n",
    "\n",
    "        #BLUE\n",
    "        low_blue = np.array([110,75,75])\n",
    "        high_blue = np.array([130,255,255])\n",
    "        blue_mask = cv2.inRange(hsv_frame, low_blue, high_blue)\n",
    "        median_b = cv2.medianBlur(blue_mask, 5)\n",
    "        blue    = cv2.bitwise_and(frame, frame, mask=median_b)\n",
    "\n",
    "\n",
    "        if median_b.any() == True:\n",
    "            blue_coord    = cv2.findNonZero(median_b)                   #get all non zero values\n",
    "            blue_centroid = np.mean(blue_coord, axis = 0)\n",
    "            cv2.circle(blue,((int)(blue_centroid[0][0]),(int)(blue_centroid[0][1])),20,(255,255,255), 2)\n",
    "\n",
    "\n",
    "        #Add red and blue\n",
    "\n",
    "        rb = cv2.add(red,blue)    \n",
    "\n",
    "        #Show \n",
    "        cv2.putText(rb, 'Robot Tracking', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"rb\", rb)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        if ('red_centroid' in locals())& ('blue_centroid' in locals()):\n",
    "            return red_centroid, blue_centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Circles Detection <a class=\"anchor\" id=\"1_2\"></a>\n",
    "\n",
    "We begin by localizing the three different colored circles with a range filter. That means we only select pixels that belong to a certain range. We have three different colors and want them to be as different as possible, so we select perfect green red and blue. In HSV color model, we can choose the color we want and then let its saturation and its intensity vary in a certain range (here between 75 and 255 for red and blue). The green is less sensitive and we thereby need to take more values in range (60-255).\n",
    "\n",
    "\n",
    "Once the pixels are selected, we have the mask and we put all other pixels to 0. We apply a median filter with a square size of 5 pixels, which will reduce noise all over the map and homogenize the circles. Indeed, without median filtering, some black dots appear in the circles which will result in less accurate calculation of centroids. \n",
    "The previous step is very important to calculate very precise centroids because we want to have the most precise position of all circles which are representing position, orientation and goal of the robot.\n",
    "\n",
    "Before sending the official centroids of the initial situation, we average the centroids on several frames captured by the camera (10 in this case). The error between all those 10 centroids has to be less than 10 pixels. If the error is to big, we wait until we have 10 centroids in a serie that will have a smaller error. This allows us to have the most precise centroids we could have.\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "<center> <b>Colored circles detection</b>\n",
    "<img src = \"image_project/CircleDetection.png\" alt=\"Drawing\" width = 500/>\n",
    "    \n",
    "The picture above shows how well the filtering allows us to get precise centroids. They are shown on the image by white circles. We can also see that the circles are really smooth which is a result of the median filtering.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Corner Detection <a class=\"anchor\" id=\"1_3\"></a>\n",
    " <br />\n",
    " We then detect obstacles corners thanks to Harris corner detector. This algorithm gives us the coordinates of all the possible corners of the map by looking at the change in brightness we have in the different axes.\n",
    "\n",
    "The map is always the same so the corners should always be the same. We could have saved the corners locally and always send the same exact corners but we decided to challenge ourselves and detect them with the camera each time and send them as much accurate as possible each time. So we have to know which corner is which. This is done by first isolating the obstacles in subspaces. As all obstacles are rectangles and thereby have 4 corners each and that we have 4 obstacles, we will have 4 subspaces of 4 corners. For the 4 corners of each obstacles, we can differentiate them by summing their coordinates. This is only possible because they are rectangles. \n",
    "  <br />\n",
    "  <br />\n",
    "  \n",
    " \n",
    "<center> <b>Obstacle corners detection</b>\n",
    "<img src = \"image_project/CornerDetection.png\" alt=\"Drawing\" width = 600/>\n",
    "    \n",
    "\n",
    "We can see on the image above that when the map is correctly placed, the corners can be well differentiated and sent the right order. So you can deduce from this map and the numbers in which order we are sending the data.\n",
    "    \n",
    "Notice also that some of the corners are not numbered. This is because they are not part of the algorithm we are using to guide the robots. But we still need them to be sure that the map is correctly aligned on the camera and that the camera zoom is correct. Indeed, the map's ratio (length/width) is adapted to the camera's ratio. This is also the reason we can differentiate the different corners. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Path planning and Global localisation <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "For our global navigation, we use Dijkstra's algorithm to identify the shortest path in a visibility graph. To do so, we defined a set of nodes, corresponding to the initial position of the robot (node A), the summits of the obstacles from our map (nodes B to K), and the desired final position (node L).   \n",
    "\n",
    "The first and last nodes of the path are defined from two color points identified using our vision algorithm, while all the others are identified by our vision component where the summits of the global obstacles are.\n",
    "Since we set the dependencies (possible routes) between all the nodes beforehand, and to avoid having to predict the possible routes from the starting point to the first summit, and from the last summit to the goal, we start by sending the robot to the closest node, and we also match the goal to its closest neighbour. While this might defeat the purpose of the shortest path algorithm, the gain in ease of calculation is worth the tradeoff in our opinion.\n",
    "\n",
    "We account for the size of the robot by virutally augmenting the dimensions of the global obstacles by 7cm all around their perimeter (represented by the grey lines in the following figure).\n",
    "\n",
    "Dijkstra’s shortest path algorithm computes the optimal path between all the summits of our obstacles (nodes B to K). All the possible routes between the nodes can be represented in the following figure, where the black polygons are the global obstacles, the grey lines are the virtual boundaries, and the black lines are the possible paths between the fixed nodes.\n",
    "\n",
    "<center> <b>Possible paths between nodes B to L (polygon summits)</b>\n",
    "<center><img src=\"image_project/possible_paths.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    " \n",
    "Sources : \n",
    "\n",
    "<a href = \"https://medium.com/cantors-paradise/dijkstras-shortest-path-algorithm-in-python-d955744c7064\">Dijkstra’s Shortest Path Algorithm in Python source </a> \n",
    "\n",
    "<a href = \"https://stackoverflow.com/questions/45002848/how-to-find-index-of-minimum-non-zero-element-with-numpy\">Stack Overflow topic for getting the closest points</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dijkstra’s Shortest Path Algorithm\n",
    "\n",
    "class Node:\n",
    "  \n",
    "    def __init__(self, data, indexloc = None):\n",
    "        self.data = data\n",
    "        self.index = indexloc\n",
    "        \n",
    "# Define the Graph class     \n",
    "class Graph:\n",
    " \n",
    "    @classmethod\n",
    "    def create_from_nodes(self, nodes):\n",
    "        return Graph(len(nodes), len(nodes), nodes)\n",
    "\n",
    "  \n",
    "    def __init__(self, row, col, nodes = None):\n",
    "        # set up an adjacency matrix\n",
    "        self.adj_mat = [[0] * col for _ in range(row)]\n",
    "        self.nodes = nodes\n",
    "        for i in range(len(self.nodes)):\n",
    "            self.nodes[i].index = i\n",
    "\n",
    "    # Conncects from node1 to node2\n",
    "    # Note row is source, column is destination\n",
    "    # Updated to allow weighted edges (supporting dijkstra's alg)\n",
    "    def connect_dir(self, node1, node2, weight = 1):\n",
    "        node1, node2 = self.get_index_from_node(node1), self.get_index_from_node(node2)\n",
    "        self.adj_mat[node1][node2] = weight\n",
    "  \n",
    "    # Optional weight argument to support dijkstra's alg\n",
    "    def connect(self, node1, node2, weight = 1):\n",
    "        self.connect_dir(node1, node2, weight)\n",
    "        self.connect_dir(node2, node1, weight)\n",
    "\n",
    "    # Get node row, map non-zero items to their node in the self.nodes array\n",
    "    # Select any non-zero elements, leaving you with an array of nodes\n",
    "    # which are connections_to (for a directed graph)\n",
    "    # Return value: array of tuples (node, weight)\n",
    "    def connections_from(self, node):\n",
    "        node = self.get_index_from_node(node)\n",
    "        return [(self.nodes[col_num], self.adj_mat[node][col_num]) for col_num in range(len(self.adj_mat[node])) if self.adj_mat[node][col_num] != 0]\n",
    "\n",
    "    # Map matrix to column of node\n",
    "    # Map any non-zero elements to the node at that row index\n",
    "    # Select only non-zero elements\n",
    "    # Note for a non-directed graph, you can use connections_to OR\n",
    "    # connections_from\n",
    "    # Return value: array of tuples (node, weight)\n",
    "    def connections_to(self, node):\n",
    "        node = self.get_index_from_node(node)\n",
    "        column = [row[node] for row in self.adj_mat]\n",
    "        return [(self.nodes[row_num], column[row_num]) for row_num in range(len(column)) if column[row_num] != 0]\n",
    "     \n",
    "  \n",
    "    def print_adj_mat(self):\n",
    "        for row in self.adj_mat:\n",
    "            print(row)\n",
    "  \n",
    "    def node(self, index):\n",
    "        return self.nodes[index]\n",
    "    \n",
    "  \n",
    "    def remove_conn(self, node1, node2):\n",
    "        self.remove_conn_dir(node1, node2)\n",
    "        self.remove_conn_dir(node2, node1)\n",
    "   \n",
    "    # Remove connection in a directed manner (nod1 to node2)\n",
    "    # Can accept index number OR node object\n",
    "    def remove_conn_dir(self, node1, node2):\n",
    "        node1, node2 = self.get_index_from_node(node1), self.get_index_from_node(node2)\n",
    "        self.adj_mat[node1][node2] = 0   \n",
    "  \n",
    "    # Can go from node 1 to node 2?\n",
    "    def can_traverse_dir(self, node1, node2):\n",
    "        node1, node2 = self.get_index_from_node(node1), self.get_index_from_node(node2)\n",
    "        return self.adj_mat[node1][node2] != 0  \n",
    "  \n",
    "    def has_conn(self, node1, node2):\n",
    "        return self.can_traverse_dir(node1, node2) or self.can_traverse_dir(node2, node1)\n",
    "  \n",
    "    def add_node(self,node):\n",
    "        self.nodes.append(node)\n",
    "        node.index = len(self.nodes) - 1\n",
    "        for row in self.adj_mat:\n",
    "            row.append(0)     \n",
    "        self.adj_mat.append([0] * (len(self.adj_mat) + 1))\n",
    "\n",
    "    # Get the weight associated with travelling from n1\n",
    "    # to n2. Can accept index numbers OR node objects\n",
    "    def get_weight(self, n1, n2):\n",
    "        node1, node2 = self.get_index_from_node(n1), self.get_index_from_node(n2)\n",
    "        return self.adj_mat[node1][node2]\n",
    "  \n",
    "    # Allows either node OR node indices to be passed into \n",
    "    def get_index_from_node(self, node):\n",
    "        if not isinstance(node, Node) and not isinstance(node, int):\n",
    "            raise ValueError(\"node must be an integer or a Node object\")\n",
    "        if isinstance(node, int):\n",
    "            return node\n",
    "        else:\n",
    "            return node.index\n",
    "\n",
    "    def dijkstra(self, node):\n",
    "        # Get index of node (or maintain int passed in)\n",
    "        nodenum = self.get_index_from_node(node)\n",
    "        # Make an array keeping track of distance from node to any node\n",
    "        # in self.nodes. Initialize to infinity for all nodes but the \n",
    "        # starting node, keep track of \"path\" which relates to distance.\n",
    "        # Index 0 = distance, index 1 = node hops\n",
    "        dist = [None] * len(self.nodes)\n",
    "        for i in range(len(dist)):\n",
    "            dist[i] = [float(\"inf\")]\n",
    "            dist[i].append([self.nodes[nodenum]])\n",
    "        \n",
    "        dist[nodenum][0] = 0\n",
    "        # Queue of all nodes in the graph\n",
    "        # Note the integers in the queue correspond to indices of node\n",
    "        # locations in the self.nodes array\n",
    "        queue = [i for i in range(len(self.nodes))]\n",
    "        # Set of numbers seen so far\n",
    "        seen = set()\n",
    "        while len(queue) > 0:\n",
    "            # Get node in queue that has not yet been seen\n",
    "            # that has smallest distance to starting node\n",
    "            min_dist = float(\"inf\")\n",
    "            min_node = None\n",
    "            for n in queue: \n",
    "                if dist[n][0] < min_dist and n not in seen:\n",
    "                    min_dist = dist[n][0]\n",
    "                    min_node = n\n",
    "            \n",
    "            # Add min distance node to seen, remove from queue\n",
    "            queue.remove(min_node)\n",
    "            seen.add(min_node)\n",
    "            # Get all next hops \n",
    "            connections = self.connections_from(min_node)\n",
    "            # For each connection, update its path and total distance from \n",
    "            # starting node if the total distance is less than the current distance\n",
    "            # in dist array\n",
    "            for (node, weight) in connections: \n",
    "                tot_dist = weight + min_dist\n",
    "                if tot_dist < dist[node.index][0]:\n",
    "                    dist[node.index][0] = tot_dist\n",
    "                    dist[node.index][1] = list(dist[min_node][1])\n",
    "                    dist[node.index][1].append(node)\n",
    "        return dist  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_from_coord(x1,y1,x2,y2):\n",
    "    '''Norm of a vector, rounded'''\n",
    "    d = np.sqrt((x2-x1)*(x2-x1)+(y2-y1)*(y2-y1))\n",
    "    return round(d,3)\n",
    "\n",
    "def matrix_computation(layout):\n",
    "    '''Get all the distances between the nodes and identify \n",
    "        the closest nodes to the starting point and the goal'''\n",
    "    d=[[] for i in range(len(layout))]\n",
    "    for i in range(len(layout)):\n",
    "        for j in range(len(layout)):\n",
    "            d[i].append(distance_from_coord(layout[i][0],layout[i][1],layout[j][0],layout[j][1]))           \n",
    "    d = np.array(d)\n",
    "    distances_to_start=d[0]\n",
    "    distances_to_end=d[-1]\n",
    "    \n",
    "    # the position/index of non-zero  minimum value in the array\n",
    "    closest_to_start = np.argmin(ma.masked_where(distances_to_start==0, distances_to_start))\n",
    "    closest_to_end = np.argmin(ma.masked_where(distances_to_end==0, distances_to_end))\n",
    "    \n",
    "    return d, closest_to_start, closest_to_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In addition to the Kalman filter (see section 4 below)**: In order to get better results, and to mitigate the deviation that happens when the robot is moving in a straight line (probably due to slipping or to the fact that both motors do not run at exactly the same speed), we correct the trajectory by regularly taking a picture, extracting the position of the robot, recalculating the angle between the current trajectory and the desired one and sending the instruction to correct the angle and to get to the next point of the path. This is done in the functions `correct_traj` and `get_to_point`.  \n",
    "Since this effect is more pronounced for long distances, the number of corrections executed between two nodes is determined by the distance that the robot has to travel. \n",
    "\n",
    "<center> <b>Trajectory correction</b>\n",
    "<center><img src=\"image_project/path_correction.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "We can observe the difference in the following videos :\n",
    "\n",
    "<center> <b>Navigation without the camera corrections with Kalman filtering</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/20DIjzSl5Ck?autoplay=1&theme=light&color=red\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x121fe6150>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"20DIjzSl5Ck\", autoplay=1, theme=\"light\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <b>Navigation with the camera corrections and the filtering</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/a1--xYKyxoQ?autoplay=1&theme=light&color=red\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x121fe7690>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"a1--xYKyxoQ\", autoplay=1, theme=\"light\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_traj(xc,yc):\n",
    "    '''correcting the trajectory of the robot to avoid drift in straight lines '''\n",
    "    red_mean,blue_mean = get_red_blue()\n",
    "    xa = red_mean[0,0]*187/1280\n",
    "    ya = 140-red_mean[0,1]*140/960\n",
    "    xb = blue_mean[0,0]*187/1280\n",
    "    yb = 140-blue_mean[0,1]*140/960\n",
    "    get_to_point(xa,ya,xb,yb,xc,yc)\n",
    "\n",
    "def get_to_point(xa,ya,xb,yb,xc,yc):\n",
    "    '''Repositionning the Thymio in the correct direction, A is the origin, C is the point to get to, \n",
    "        B is a reference point (e.g. second point on the Thymio) to compute the direction to align to.'''\n",
    "    u=[xb-xa,yb-ya]\n",
    "    v=[xc-xa,yc-ya]\n",
    "    angle=degrees(acos(np.dot(u,v)/(np.linalg.norm(u)*np.linalg.norm(v))))\n",
    "    distance=np.linalg.norm(v)\n",
    "    speed=67.5\n",
    "    if u[0]*v[1] - u[1]*v[0] < 0:\n",
    "        angle = -angle;    \n",
    "    rotation(angle)\n",
    "    #angles = rotation(angle,xb,yb)\n",
    "    #ang_speeds =  np.array([])\n",
    "    #for i in range(np.size(angles)):\n",
    "    #    ang_speeds = np.append(ang_speeds,angles[i]/(0.5*(i+1)))\n",
    "    #angular=kalman_rotation(angles,ang_speeds)\n",
    "    #rotation(angle-angular[0,0])\n",
    "    if distance <= 20:\n",
    "        distances = translation(distance,xa,ya)\n",
    "        speeds=  np.array([])\n",
    "        for i in range(np.size(distances)):\n",
    "            speeds = np.append(speeds,distances[i]/(0.5*(i+1)))\n",
    "        if (np.size(distances) != 0):\n",
    "            x=kalman(distances,speeds)\n",
    "            translation(distance-x[0,0])     \n",
    "    elif distance > 20 and distance <= 40:\n",
    "        distances = translation(distance/2,xa,ya)\n",
    "        speeds=  np.array([])\n",
    "        for i in range(np.size(distances)):\n",
    "            speeds = np.append(speeds,distances[i]/(0.5*(i+1)))\n",
    "        if (np.size(distances) != 0):\n",
    "            x=kalman(distances,speeds)\n",
    "            translation(distance/2-x[0,0])\n",
    "        correct_traj(xc,yc)\n",
    "    elif distance > 40:\n",
    "        distances = translation(distance/3,xa,ya)\n",
    "        speeds =  np.array([])\n",
    "        for i in range(np.size(distances)):\n",
    "            speeds = np.append(speeds,distances[i]/(0.5*(i+1)))\n",
    "        if (np.size(distances) != 0):\n",
    "            x=kalman(distances,speeds)\n",
    "            translation(distance/3-x[0,0])\n",
    "        correct_traj(xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positionning(layout,blue_mean):    \n",
    "    '''conversion from pixels to cm'''\n",
    "    for i in range(len(layout)):\n",
    "        layout[i][0]*=187/1280\n",
    "        layout[i][1]*=140/960\n",
    "        #adjusting the origin of the grid to the following path planning algorithm\n",
    "        #in vision, the origin is at the top left corner whereas in planning it is at the bottom left\n",
    "        layout[i][1]=140-layout[i][1]\n",
    "\n",
    "    #adding a 7cm \"invisible\" border around the obtacles to account for the Thymio's width\n",
    "    border=7\n",
    "\n",
    "    layout[1][0]+=border\n",
    "    layout[1][1]+=border\n",
    "    layout[2][0]+=border\n",
    "    layout[2][1]-=border\n",
    "    layout[3][0]-=border\n",
    "    layout[3][1]-=border\n",
    "    layout[4][0]+=border\n",
    "    layout[4][1]-=border\n",
    "    layout[5][0]-=border\n",
    "    layout[5][1]+=border\n",
    "    layout[6][0]+=border\n",
    "    layout[6][1]+=border\n",
    "    layout[7][0]-=border\n",
    "    layout[7][1]+=border\n",
    "    layout[8][0]+=border\n",
    "    layout[8][1]+=border\n",
    "    layout[9][0]+=border\n",
    "    layout[9][1]-=border\n",
    "    layout[10][0]-=border\n",
    "    layout[10][1]-=border\n",
    "\n",
    "    dist=matrix_computation(layout)\n",
    "\n",
    "    #define the nodes and the dependencies between them\n",
    "    a = Node(layout[0]) #starting point, red point\n",
    "    b = Node(layout[1])\n",
    "    c = Node(layout[2])\n",
    "    d = Node(layout[3])\n",
    "    e = Node(layout[4])\n",
    "    f = Node(layout[5])\n",
    "    g = Node(layout[6])\n",
    "    h = Node(layout[7])\n",
    "    i = Node(layout[8])\n",
    "    j = Node(layout[9])\n",
    "    k = Node(layout[10])\n",
    "    l = Node(layout[11]) #goal, green point\n",
    "\n",
    "    nodes_list=[a,b,c,d,e,f,g,h,i,j,k,l]\n",
    "    w_graph = Graph.create_from_nodes(nodes_list)\n",
    "\n",
    "    #define all the possible connections between nodes\n",
    "    w_graph.connect(a,nodes_list[dist[1]],dist[0][0][dist[1]])\n",
    "    w_graph.connect(b,c,dist[0][1][2])\n",
    "    w_graph.connect(b,d,dist[0][1][3])\n",
    "    w_graph.connect(b,f,dist[0][1][5])\n",
    "    w_graph.connect(b,g,dist[0][1][6])\n",
    "    w_graph.connect(c,d,dist[0][2][3])\n",
    "    w_graph.connect(c,f,dist[0][2][5])\n",
    "    w_graph.connect(c,e,dist[0][2][4])\n",
    "    w_graph.connect(d,e,dist[0][3][4])\n",
    "    w_graph.connect(d,f,dist[0][3][5])\n",
    "    w_graph.connect(d,g,dist[0][3][6])\n",
    "    w_graph.connect(d,k,dist[0][3][10])\n",
    "    w_graph.connect(e,f,dist[0][4][5])\n",
    "    w_graph.connect(e,g,dist[0][4][6])\n",
    "    w_graph.connect(e,h,dist[0][4][7])\n",
    "    w_graph.connect(e,k,dist[0][4][10])\n",
    "    w_graph.connect(f,h,dist[0][5][7])\n",
    "    w_graph.connect(h,i,dist[0][7][8])\n",
    "    w_graph.connect(h,k,dist[0][7][10])\n",
    "    w_graph.connect(i,j,dist[0][8][9])\n",
    "    w_graph.connect(j,k,dist[0][9][10])\n",
    "    w_graph.connect(nodes_list[dist[2]],l,dist[0][dist[1]][11])\n",
    "\n",
    "    #computing the path to follow\n",
    "    path=([(weight, [n.data for n in node]) for (weight, node) in w_graph.dijkstra(a)])\n",
    "\n",
    "    #setting the coordinates of the second reference point captured on the Thymio, \n",
    "    #and used to determine the rotation needed to align and start the sequence\n",
    "    xb = blue_mean[0,0]*187/1280\n",
    "    yb = 140-blue_mean[0,1]*140/960\n",
    "\n",
    "    #launching the global positionning sequence\n",
    "    for i in range(len(path[-1][1])-1):\n",
    "        [xa,ya]=path[-1][1][i]\n",
    "        [xc,yc]=path[-1][1][i+1]\n",
    "        get_to_point(xa,ya,xb,yb,xc,yc)\n",
    "        [xb,yb]=[2*xc-xa,2*yc-ya]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Local Avoidance<a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "The goal of obstacle avoidance algorithms is to avoid collisions with unpredictable objects. At any time, the thymio must be able to avoid an object. It’s an independent task mode to the global navigation. For this, we will use the 7 sensors provided by the thymio.\n",
    "\n",
    "## 3.1. Odometry<a class=\"anchor\" id=\"3_1\"></a>\n",
    "When an unlisted object is detected, its proximity sensors alert it. Estimate and tracking the position is therefore required to bypass the obstacle and recover the initial intended path. It's exactly the use of odometry.\n",
    "We proceeded as follows: \n",
    "- Empiricaly, we find that the robot make a rotation of 1 degree in 0.026 sec.\n",
    "- Empirically, we find that the robot move forward 1 centimeter in 0.15 second.\n",
    "- When moving forward, we look at the front proximity sensors if there is a unexpected obstacle. **If there is one, we reduce the distance to advance by the distance that the robot avoid.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(degree,xb=0,yb=0):\n",
    "    '''Make a rotation of degree (can be positiv or negative)'''\n",
    "    t=abs(0.026*degree)\n",
    "    sleep_time=t/100\n",
    "    counter=1\n",
    "    angles=np.array([])\n",
    "    then=time.time()\n",
    "    if degree > 0:\n",
    "        th.set_var('motor.left.target',2**16-100)\n",
    "        th.set_var('motor.right.target',100)\n",
    "    else:\n",
    "        th.set_var('motor.left.target',100)\n",
    "        th.set_var('motor.right.target',2**16-100)\n",
    "    while 1:\n",
    "        now=time.time()\n",
    "        #if now-then >= 0.5:\n",
    "        #    angles = kalman_filling_rot(xb,yb,angles)\n",
    "        #    then=time.time()\n",
    "        counter +=1\n",
    "        time.sleep(sleep_time)\n",
    "        if counter == 100:\n",
    "            break\n",
    "    th.set_var('motor.left.target', 0)\n",
    "    th.set_var('motor.right.target',0)\n",
    "    time.sleep(0.5)\n",
    "    return angles\n",
    "\n",
    "def translation(distance,xa = 0, ya=0):\n",
    "    '''translation(distance) make a displacement of 'distance' cm and process local avoidance if needed, additionnaly,\n",
    "    make the array of the positions to adjust them with the kalman filter. '''\n",
    "    if distance<0:\n",
    "        th.set_var('motor.left.target',2**16-200)\n",
    "        th.set_var('motor.right.target',2**16-200) \n",
    "    else:\n",
    "        th.set_var('motor.left.target',200)\n",
    "        th.set_var('motor.right.target',200)\n",
    "    distance_avoid = 20.5\n",
    "    t = 0.15*abs(distance) \n",
    "    sleep_time = t / 100\n",
    "    counter = 1\n",
    "    counter_avoid = 1\n",
    "    avoid = 0\n",
    "    backped= 0\n",
    "    distances = np.array([])\n",
    "    then = time.time()\n",
    "    while 1:\n",
    "        distance_done = counter *sleep_time/0.15\n",
    "        now = time.time()\n",
    "        if (now-then) >= 0.5 :\n",
    "            distances = kalman_filling(xa,ya,distances)\n",
    "            then=time.time()\n",
    "        flag = start_avoidance()\n",
    "       \n",
    "        if flag != 0: # knowing that the distance avoid is 20.7 cm, the remaining distance to travel is distance-distance_avoid\n",
    "            if distance_done+distance_avoid > distance :\n",
    "                t = 0.157*(distance_avoid - distance + distance_done)\n",
    "                backped = 1\n",
    "            else:\n",
    "                t = 0.157*(distance-distance_avoid-distance_done)\n",
    "            avoid = 1\n",
    "        if avoid:\n",
    "            if backped: # if we go too far, the robot go back to the desired position\n",
    "                th.set_var('motor.left.target',2**16-200)\n",
    "                th.set_var('motor.right.target',2**16-200)\n",
    "            else:\n",
    "                th.set_var('motor.left.target',200)\n",
    "                th.set_var('motor.right.target',200)\n",
    "            time.sleep(t)\n",
    "            break\n",
    "        else :\n",
    "            time.sleep(sleep_time)\n",
    "            counter +=1\n",
    "            if distance<0:\n",
    "                th.set_var('motor.left.target',2**16-200)\n",
    "                th.set_var('motor.right.target',2**16-200) \n",
    "            else:    \n",
    "                th.set_var('motor.left.target',200)\n",
    "                th.set_var('motor.right.target',200)\n",
    "        if counter == 100 :\n",
    "            break\n",
    "    th.set_var('motor.left.target',0)\n",
    "    th.set_var('motor.right.target',0)\n",
    "    return distances\n",
    "\n",
    "def translation_avoid(distance):#\n",
    "    '''translation_avoid(distance) is use if the local avoidance is not needed '''\n",
    "    th.set_var('motor.left.target',200)\n",
    "    th.set_var('motor.right.target',200)\n",
    "    t = 0.157*distance\n",
    "    time.sleep(t)\n",
    "    th.set_var('motor.left.target',0)\n",
    "    th.set_var('motor.right.target',0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Sensors<a class=\"anchor\" id=\"3_2\"></a>\n",
    "\n",
    "### Improvement of visibility of sensors\n",
    "One difficulty of this project was the sensitivity of the sensors. Indeed, their accuracy was very variable depending on the environment and very unstable. To improve their sensitivity and the distance at which they detect an object, we added reflective strips on detachable obstacles (such as bicycles, road signs, etc...). The image bellow shows the different distances at which the object is seen, with and without the reflective strip so that it's visible to proximity sensors. The distance has more than doubled.\n",
    "\n",
    "<center> <b>Improvement of sensors visibility</b> </center>\n",
    "<img src=\"image_project/improvevisibility.png\" alt=\"improve\" style=\"width: 400px;\"/>\n",
    "                                                 \n",
    "                                           \n",
    "\n",
    "\n",
    "\n",
    "## 3.3. Algorithm <a class=\"anchor\" id=\"3_3\"></a>\n",
    "\n",
    "The robot's motors turn at a constant speed for a fixed period of time. During this period, we need to avoid unexpected obstacles. We compute the local avoidance in 4 different functions below.\n",
    "\n",
    "### Start avoidance \n",
    "The goal of this function is to combine the 4 others together. In addition, it's the function that receives the values of the sensors and the one which decides which 'avoidance type' to follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_avoidance():\n",
    "    ''' If there is an obstacle, start_avoidance() launch the local avoidance '''\n",
    "    counter = 0 \n",
    "    THRESHOLD_SENSOR_1= 3500\n",
    "    THRESHOLD_SENSOR= 3800\n",
    "    THRESHOLD_SENSOR_2= 4300\n",
    "    THRESHOLD_SENSOR_3 = 3800\n",
    "    flag = 0\n",
    "    \n",
    "    #detection of an unprevisible obstacle\n",
    "    for i in range(10):\n",
    "        sensors0 = th[\"prox.horizontal\"][0]\n",
    "        sensors1 = th[\"prox.horizontal\"][1]\n",
    "        sensors2 = th[\"prox.horizontal\"][2]\n",
    "        sensors3 = th[\"prox.horizontal\"][3]\n",
    "        sensors4 = th[\"prox.horizontal\"][4]\n",
    "        \n",
    "        #detection of an object\n",
    "        if((sensors0 >= THRESHOLD_SENSOR_2) or (sensors1 >= THRESHOLD_SENSOR) or (sensors2 >= THRESHOLD_SENSOR) or (sensors3 >= THRESHOLD_SENSOR)) or (sensors4 >= THRESHOLD_SENSOR_2):\n",
    "            counter += 1\n",
    "        else: \n",
    "            counter = 0\n",
    "    if counter == 10 :\n",
    "        #detecte if the object is in front\n",
    "        if (sensors1 >= THRESHOLD_SENSOR_1 and sensors3 >= THRESHOLD_SENSOR_1) or (sensors2 >= THRESHOLD_SENSOR_3) :\n",
    "            front=1\n",
    "        else:\n",
    "            front =0\n",
    "        #detection of right sensors\n",
    "        if (sensors0+sensors1< sensors3+sensors4):\n",
    "            detect_right=1\n",
    "        #detection of left sensors\n",
    "        else:\n",
    "            detect_right=0\n",
    "            \n",
    "        if front ==1 :\n",
    "            avoidance_type(0)\n",
    "            flag = 1\n",
    "        else:\n",
    "            if detect_right==1 :\n",
    "                avoidance_type(1)\n",
    "            elif (sensors0 >= THRESHOLD_SENSOR_2 or sensors1 >= THRESHOLD_SENSOR_2):\n",
    "                avoidance_type(2)\n",
    "            flag = 1\n",
    "    return flag\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The avoidance type \n",
    "First, we need to know where the obstacle is relative to the robot. If the obstacle is in front, the robot does a half circle around it. If the obstable is on left or right of the robot, the robot does a half rectancle around it. We decide to define two differents routines to show more clearly which avoidance the robot does.\n",
    "Secondly, for the half circle avoidance, if the robot goes straight to a global obstacle, it must back off, turn around and do the half circle routine in the other direction of rotation. \n",
    "\n",
    "\n",
    "#### <center>Half circle Avoidance:\n",
    "<center>This avoidance type is here to show that if the obstacle is in front, it is possible to go around it in a half circle. In addition to this, if there is a fixed obstacle, we make the avoidance with the other half circle to not go through the obstacle.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/cNI3L-d8oGc?autoplay=1&theme=light&color=red\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x121fe73d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"cNI3L-d8oGc\", autoplay=1, theme=\"light\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Right, left avoidance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/NuEBW9fY-fs?autoplay=1&theme=light&color=red\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x1220b8d90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"NuEBW9fY-fs\", autoplay=1, theme=\"light\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoidance_type(type_of_avoidance,direction =0):\n",
    "    '''avoidance_type(type_of_avoidance,direction =0) select the type of avoidance we have to do.'''\n",
    "    if type_of_avoidance ==0 :\n",
    "        if direction ==0:\n",
    "            stabilisation(direction)\n",
    "            time.sleep(0.5)\n",
    "            rotation(90)\n",
    "            line= bypass_obstacle(direction)\n",
    "            if line == 0:\n",
    "                turn_90_perpen_obstacle(direction)\n",
    "            else:\n",
    "                direction =1 \n",
    "                stabilisation(direction)\n",
    "                time.sleep(0.5)\n",
    "                bypass_obstacle(direction)\n",
    "                turn_90_perpen_obstacle(direction)\n",
    "\n",
    "    #right avoidance             \n",
    "    elif type_of_avoidance ==1 :\n",
    "        rotation(90)\n",
    "        translation_avoid(10)\n",
    "        rotation(-90)\n",
    "        translation_avoid(20.7)\n",
    "        rotation(-90)\n",
    "        translation_avoid(10)\n",
    "        rotation(90)\n",
    "    #left_avoidance\n",
    "    elif type_of_avoidance ==2 :\n",
    "        rotation(-90)\n",
    "        translation_avoid(10)\n",
    "        rotation(+90)\n",
    "        translation_avoid(20.7)\n",
    "        rotation(+90)\n",
    "        translation_avoid(10)\n",
    "        rotation(-90)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bypass obstacle\n",
    "This is the fonction that makes the Thymio go in a half circle around the obtacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bypass_obstacle(direction):\n",
    "    '''bypass_obstacle(direction) avoid the objet with a half circle.'''\n",
    "    THRESHOLD_HIGH= 4200\n",
    "    THRESHOLD_LOW=0\n",
    "    SPEED=100\n",
    "    line = 0\n",
    "    then = time.time()\n",
    "    now = time.time()\n",
    "    if direction ==0:\n",
    "        while now-then <=5.4:\n",
    "            now = time.time() \n",
    "            th.set_var(\"motor.left.target\", 280)\n",
    "            th.set_var(\"motor.right.target\", 100)\n",
    "            #detect if there is a fixed obstacle\n",
    "            if th[\"prox.horizontal\"][2] > THRESHOLD_HIGH :\n",
    "                th.set_var(\"motor.left.target\", 2**16-280)\n",
    "                th.set_var(\"motor.right.target\", 2**16-100)\n",
    "                time.sleep(now-then)\n",
    "                line=1\n",
    "                break\n",
    "    #take the other path if there is a fixed obstacle on the road               \n",
    "    else:\n",
    "        while now-then <=5.4:\n",
    "            now = time.time() \n",
    "            if  th[\"prox.horizontal\"][4] > THRESHOLD_HIGH:\n",
    "                th.set_var(\"motor.left.target\", SPEED)\n",
    "                th.set_var(\"motor.right.target\", 2**16-SPEED)\n",
    "            elif th[\"prox.horizontal\"][4] < THRESHOLD_LOW:\n",
    "                th.set_var(\"motor.left.target\", 2**16-SPEED)\n",
    "                th.set_var(\"motor.right.target\", SPEED)\n",
    "            else:\n",
    "                th.set_var(\"motor.left.target\", 100)\n",
    "                th.set_var(\"motor.right.target\", 280) \n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Front stabilization\n",
    "\n",
    "This function is made to ensure that the thymio will be perpendicular to the object before it starts its rotation.\n",
    "<center> <b>Stabilization\n",
    "<center> <img src=\"image_project/stabilisation.png\" alt=\"Drawing\" style=\"width: 250px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stabilisation(direction):\n",
    "    '''stabilisation(direction) stabilise the Thymio to be perpendicular to the obstacle'''\n",
    "    DELTA_TO_TURN = 200\n",
    "    SPEED_MAX_TURN = 100\n",
    "    THRESHOLD_SENSORS_FRONT =500\n",
    "    THRESHOLD_REGRESSION =400\n",
    "    OFFSET=20\n",
    "    stop=0\n",
    "    sensor1= th[\"prox.horizontal\"][1]\n",
    "    sensor3= th[\"prox.horizontal\"][3]\n",
    "    diff_captor_back = sensor1 - sensor3\n",
    "    \n",
    "    if direction==0 :\n",
    "        #the next condition adjust the thymio to be in front of the obstacle\n",
    "        while (abs(diff_captor_back) > DELTA_TO_TURN) or (th[\"prox.horizontal\"][1]<THRESHOLD_SENSORS_FRONT) or (th[\"prox.horizontal\"][3]<THRESHOLD_SENSORS_FRONT):\n",
    "            if (abs(diff_captor_back)<THRESHOLD_REGRESSION) and (th[\"prox.horizontal\"][1]>THRESHOLD_SENSORS_FRONT) and (th[\"prox.horizontal\"][3]>THRESHOLD_SENSORS_FRONT):\n",
    "                velocity = abs(diff_captor_back)/5\n",
    "                velocity = round(velocity)\n",
    "            else:\n",
    "                velocity=SPEED_MAX_TURN\n",
    "            if diff_captor_back>=0:\n",
    "                th.set_var(\"motor.left.target\", 2**16-velocity)\n",
    "                th.set_var(\"motor.right.target\", velocity)\n",
    "            else:\n",
    "                th.set_var(\"motor.left.target\", velocity)\n",
    "                th.set_var(\"motor.right.target\", 2**16-velocity)\n",
    "            sensor1= th[\"prox.horizontal\"][1]\n",
    "            sensor3= th[\"prox.horizontal\"][3]\n",
    "            diff_captor_back = sensor1 - sensor3\n",
    "    else:\n",
    "        rotation(-180)\n",
    "        \n",
    "    th.set_var(\"motor.left.target\", 0)\n",
    "    th.set_var(\"motor.right.target\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back stabilization\n",
    "In this function, we want to be sure that the robot has the same angle as the one he had at the beginning of the avoidance routine. To do so, we compute the following function which virtually uses a PID to be more accurate.\n",
    "<center><b> Back Stabilization\n",
    "<center><img src=\"image_project/obstacle.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_90_perpen_obstacle(direction):\n",
    "    '''turn_90_perpen_obstacle(direction) do the same things as stabilisation(direction) but with the sensors in the back'''\n",
    "    DELTA_TO_TURN = 30\n",
    "    SPEED_MAX_TURN = 100\n",
    "    THRESHOLD_SENSORS_BACK =500\n",
    "    THRESHOLD_REGRESSION =400\n",
    "    OFFSET=20\n",
    "    stop=0\n",
    "    diff_captor_back = th[\"prox.horizontal\"][6] - th[\"prox.horizontal\"][5]\n",
    "    while (abs(diff_captor_back) > DELTA_TO_TURN) or (th[\"prox.horizontal\"][6]<THRESHOLD_SENSORS_BACK) or (th[\"prox.horizontal\"][6]<THRESHOLD_SENSORS_BACK):\n",
    "        if (abs(diff_captor_back)<THRESHOLD_REGRESSION) and (th[\"prox.horizontal\"][6]>THRESHOLD_SENSORS_BACK) and (th[\"prox.horizontal\"][6]>THRESHOLD_SENSORS_BACK):\n",
    "            velocity = abs(diff_captor_back)/5 + OFFSET\n",
    "            velocity = round(velocity)\n",
    "        else:\n",
    "            velocity=SPEED_MAX_TURN\n",
    "        if direction == 0:\n",
    "            if diff_captor_back>=0:\n",
    "                th.set_var(\"motor.left.target\", 2**16-velocity)\n",
    "                th.set_var(\"motor.right.target\", velocity)\n",
    "            else:\n",
    "                th.set_var(\"motor.left.target\", velocity)\n",
    "                th.set_var(\"motor.right.target\", 2**16-velocity)\n",
    "            diff_captor_back = th[\"prox.horizontal\"][6] - th[\"prox.horizontal\"][5]\n",
    "        else:\n",
    "            if diff_captor_back>=0:\n",
    "                th.set_var(\"motor.left.target\", velocity)\n",
    "                th.set_var(\"motor.right.target\", 2**16-velocity)\n",
    "            else:\n",
    "                th.set_var(\"motor.left.target\", 2**16-velocity)\n",
    "                th.set_var(\"motor.right.target\", velocity)\n",
    "            diff_captor_back = th[\"prox.horizontal\"][5] - th[\"prox.horizontal\"][6]\n",
    "    for i in range(3):\n",
    "        th.set_var(\"motor.left.target\", DELTA_TO_TURN)\n",
    "        th.set_var(\"motor.right.target\", 2**16-DELTA_TO_TURN)\n",
    "    time.sleep(0.2)\n",
    "        \n",
    "    th.set_var(\"motor.left.target\", 300)\n",
    "    th.set_var(\"motor.right.target\",300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Limitations of local navigation<a class=\"anchor\" id=\"3_4\"></a>\n",
    "\n",
    "### Odometry\n",
    "Because of the fact that the motor, the acceleration and the speed are not really accurate, we cannot have a perfect localization of the robot. We find the needed parameters empirically on the thymio *TP401*. The parameters and the precision vary from one robot to another. To correct the uncertainties, we used  [4. Kalman filtering](#4).\n",
    "\n",
    "### Unexpected case\n",
    "There are some unexpected cases that the robot cannot dodge. For example, if the obstacle is at the point where the robot needs to get to, to follow the path planning, it will dodge it but it will backtrack to get back in position and the user has to manually remove the obstacle in order for the robot to go to the correct position. In addition, if the obstacle splits the black rectangle in 2 identical parts, the robot will backtrack after the first time it meets the rectangle but not the second time. It will go to the correct position but will go through the obstacle (which is an unwanted behaviour). Fortunately, this is really rare.\n",
    "\n",
    "### Sensors and luminosity\n",
    "We find that the values returned by the sensors depend on the luminosity of the room so we will need to calibrate some values before the presentation to be sure to have some accurate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/GMUoFIqFEWg?autoplay=1&theme=light&color=red\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x12204f450>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"GMUoFIqFEWg\", autoplay=1, theme=\"light\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kalman filtering <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Translation <a class=\"anchor\" id=\"4_1\"></a>\n",
    "\n",
    "**Goal of Kalman:**\n",
    "\n",
    "The goal is to estimate the position and the speed  with kalman filter when it moves. \n",
    "Like the wheels don’t have encoders, two different measurements are used: \n",
    "\n",
    "- The vision tracking (from the camera logitech)\n",
    "- The speed  (which the thymio moves)\n",
    "\n",
    "**Methodology**: \n",
    "\n",
    "The Thymio robot moves at constant speed across a map. The actual mean velocity of the two wheels and the tracking of the camera are sent to Python. The programm receives these values, predicts and updates the estimated velocitys and positions of the robot. Since our noise can be considered as gaussian (due to the camera), we can and will use the basic concept of Kalman filter from the course <a href ='https://moodle.epfl.ch/course/view.php?id=15293'>*basic of mobile robotics*</a>. Below stands the schema of Kalman.\n",
    "\n",
    "\n",
    "<center> <b> Kalman Filter</b>\n",
    "<figure>\n",
    "<img src=\"image_project/concept Kalmann filter.png\" alt=\"concept Kalmann filter\" style=\"width: 400px;\"/> \n",
    "<figcaption> <center> Figure X: Kalman filter principle (from wikipedia)\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "The measured vector of the system is z (the tracking camera knows always the position of the Thymio). \n",
    "Also we are based on the code: <a href= 'https://medium.com/@jaems33/understanding-kalman-filters-with-python-2310e87b8f48'> Understanding kalman filters with python</a> and <a href='http://en.wikipedia.org/wiki/Kalman_filter'>Kalman Filter </a>.\n",
    "\n",
    "**Model parameters:**\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "x_{k+1}=Ax_k+w_k \\\\\n",
    "\\\\\n",
    "\\\\\n",
    "where\\ w_k\\, the\\ noise\\ mean\\ zero\\ and\\ Q\\ the\\ covariance \\\\\n",
    "y_k= Cx_k +v_k\\\\\n",
    "\\\\\n",
    "where\\ v_k\\,\\ the\\ noise\\ mean\\ zero\\ and\\ R\\ the\\ covariance \\\\\n",
    "\\end{equation}\n",
    "The Function will return the predicted values and updated the new values for x and P.\n",
    "- x state 2-tuple of location, position, and velocity : \n",
    "\\begin{equation}\n",
    "x_k=[x\\ \\ \\ v]^T\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- P is the uncertainty convariance matrix of error\n",
    "- A matrix makes the “linear model”.\n",
    "- Measurement: observed position from the camera tracking.\n",
    "- R: the measurement noise covariance matrix. For simplicity, R can be assumed to be diagonal (auto-correlation matrix) of dimension two. On his diagonal, the square of the standard deviation of the sensor noise. (Indeed, the noise of the sensors are considered Gaussian and unrelated to each other)\n",
    "- Q: is the covariance (the motion noise). It can be assumed to be diagonal with in his diagonal element qp, qv.\n",
    "- C: measurement function\n",
    "- The variable “t” takes the measure of the time elapsed from a phase to the next (sampling period). The time is essential for the state estimation.\n",
    "\n",
    "**Identification parameter (translation**)\n",
    "\n",
    "_R: The covariance of the observation noise:_\n",
    "\n",
    "The covariance of the observation noise has been identify with the *tracking of the camera* . The value of $rp$ can be found by processing the measurements while the output of the system is held constant. In this case, only noise remains in the data after the mean is removed. Many tests of camera tracking have been performed. The tracking of position is done with the red circle. In width, we have 0.6 pixel of standard deviation and in height is 0.4 pixel. Like 1 pixel= 1.46 mm, we have so \n",
    "\\begin{equation}\n",
    "\\sigma_1 =0.6*{1.46}=0.87mm \\\\\n",
    "\\sigma_2 =0.4*{1.46}=0.62mm\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "\\sigma = \\sqrt\\frac{\\sigma_1^2 \\ + \\sigma_2^2}{2} = \\sqrt{\\frac{0.87^2+0.62^2}{2}}= 0.75 mm \\\\\n",
    "\\end{equation}\n",
    "\n",
    "We put a weight of 10 times to the velocity.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\ Standard\\ Deviation\\ of\\ camera\\ tracking\\ measurement: \\sqrt{r_p} = 0.75mm =0.075 cm \\\\\n",
    "\\ Standard\\ Deviation\\ of\\ camera\\ tracking\\ measurement: \\sqrt{r_v} = 7.5 mm/s = 0.75cm/s \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "_Q: The covariance of process noise (same shape as P):_\n",
    "\n",
    "The covariance on position and speed. We estimate by the last session exercise with Sysquake application. Using the Sysquake application, the speed variance in Thymio units is 197. Converted to $\\frac{mm^2}{s^2}$, we obtain 197 · 0.33752 ≈ 22 $\\frac{mm^2}{s^2}$. We assume half of it is caused by perturbations to the states, $qv$ = $11 \\frac{mm^2}{s^2}$. The value of $rp$ was taken arbitrarily at 0.04mm.\n",
    "\\begin{eqnarray}\n",
    "\\ Standart\\ Deviation\\ on\\ position\\ state:  \\sqrt{q_p} = 0.2 mm = 0.02 cm\\\\\n",
    "\\ Standart\\ Deviation\\ on\\ position\\ state : \\sqrt{q_v}= 3.4 mm/s = 0.34 cm/s\\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kalman\n",
    "\n",
    "def prediction2d(x, v, t):\n",
    "    A = np.array([[1, t],\n",
    "                  [0, 1]])\n",
    "    X = np.array([[x],\n",
    "                  [v]])\n",
    "    #B = np.array([[0.5 * t ** 2],\n",
    "     #             [t]])\n",
    "    X_prime = A.dot(X) #+ B.dot(a)\n",
    "    return X_prime\n",
    "\n",
    "\n",
    "def covariance2d(sigma1, sigma2):\n",
    "\n",
    "    cov_matrix = np.array([[sigma1 ** 2, 0],\n",
    "                           [0, sigma2 ** 2]])\n",
    "    return np.diag(np.diag(cov_matrix))\n",
    "\n",
    "def kalman(distances,speed):\n",
    "    \"\"\"Estimate the position and the speed in rotation with kalman filter when the robot moves\"\"\"\n",
    "    x_observations = distances\n",
    "    v_observations = speed\n",
    "    print(\"x_observations :\",x_observations)\n",
    "    print(\"v_observations :\",v_observations)\n",
    "    z = np.c_[x_observations, v_observations]\n",
    "\n",
    "    # Initial Conditions\n",
    "    #a = 0.0001    # Acceleration\n",
    "    v = 20*0.3375  # Cm/s\n",
    "    t = 0.5        # Difference in time\n",
    "\n",
    "    # Process / Estimation Errors\n",
    "    error_est_x = 0.02   # sqrt(qp)\n",
    "    error_est_v = 0.34   # sqrt(qv)\n",
    "\n",
    "    # Observation Errors\n",
    "    error_obs_x = 0.075  # sqrt(rp) Uncertainty in the measurement\n",
    "    error_obs_v = 0.75   # sqrt(rv)\n",
    "\n",
    "    # Initial Estimation Covariance Matrix\n",
    "    P = covariance2d(error_est_x, error_est_v)\n",
    "    A = np.array([[1, t],\n",
    "                  [0, 1]])\n",
    "\n",
    "    # Initial State Matrix\n",
    "    X = np.array([[z[0][0]],\n",
    "                  [v]])\n",
    "    n = len(z[0])\n",
    "\n",
    "    for data in z[1:]:\n",
    "        X = prediction2d(X[0][0], X[1][0], t)\n",
    "        # set off-diagonal terms to 0.\n",
    "        P = np.diag(np.diag(A.dot(P).dot(A.T)))\n",
    "\n",
    "        # Calculating the Kalman Gain\n",
    "        H = np.identity(n)\n",
    "        R = covariance2d(error_obs_x, error_obs_v)\n",
    "        S = H.dot(P).dot(H.T) + R\n",
    "        K = P.dot(H).dot(inv(S))\n",
    "\n",
    "        # Reshape the new data into the measurement space.\n",
    "        Y = H.dot(data).reshape(n, -1)\n",
    "\n",
    "        # Update the State Matrix\n",
    "        # Combination of the predicted state, measured values, covariance matrix and Kalman Gain\n",
    "        X = X + K.dot(Y - H.dot(X))\n",
    "\n",
    "        # Update Process Covariance Matrix\n",
    "        P = (np.identity(len(K)) - K.dot(H)).dot(P)\n",
    "    print(\"Kalman estimation: \",X)\n",
    "    return X\n",
    "\n",
    "def kalman_filling(xa,ya,distances):         \n",
    "    red_mean, blue_mean = get_red_blue()\n",
    "    xred = red_mean[0,0]*187/1280\n",
    "    yred = 140-red_mean[0,1]*140/960\n",
    "    w=[xred-xa,yred-ya]\n",
    "    distances = np.append(distances,np.linalg.norm(w))\n",
    "    return distances\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Rotation <a class=\"anchor\" id=\"4_2\"></a>\n",
    "\n",
    "It's basically the same that the *kalman translation* code.\n",
    "We change of course the model parameters with rotation and we identify as well:\n",
    "\n",
    "**Model parameters**\n",
    "\n",
    "The Function will return the predicted and updated new values for x and P.\n",
    "- x state 2-tuple of angular position and angular velocity :\n",
    "\n",
    "\\begin{equation}\n",
    "x_k=[\\psi\\ \\ \\ \\dot{\\psi}]^T\n",
    "\\end{equation}\n",
    "\n",
    "- P is the uncertainty convariance matrix of error.\n",
    "- A matrix makes the “linear model”.\n",
    "- Measurement: observed position from the camera tracking.\n",
    "- R: the measurement noise covariance matrix. For simplicity, R can be assumed to be diagonal (auto-correlation matrix) of dimension two. On his diagonal, the square of the standard deviation of the sensor noise. (Indeed, the noise of the sensors are considered Gaussian and unrelated to each other)\n",
    "- Q: is the covariance (the motion noise). It can be assumed to be diagonal with in his diagonal element qp, qv.\n",
    "- C: measurement function\n",
    "- The variable “t” takes the measure of the time elapsed from a phase to the next (sampling period). The time is essential for the state estimation.\n",
    "\n",
    "**Identification parameters (rotation)**\n",
    "\n",
    "_R: The covariance of the observation noise:_\n",
    "\n",
    "The $rp$ values can be found by processing the measurements while the output of the system is held constant. In this case, only noise remains in the data after the mean is removed. Many tests of camera tracking have been performed. The tracking of rotation is done with red and blue circles. We have previously calculated the standard deviation for the red circle (0.75mm). We calculated the blue one by the method as the one in the Kalman translation section (0.81mm). The average for both colors gives the sum of the variance:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma = \\sqrt{0.75^2+0.81^2}\\approx 1.1mm \\\\\n",
    "\\end{equation} \n",
    "\n",
    "Pay attention that we have now in rotation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha=\\frac{x}{R} \\\\\n",
    "\\end{equation}\n",
    "\n",
    "with R is the distance between one wheel and the center. R=47mm\n",
    "\\begin{equation}\n",
    "\\alpha=\\frac{1.1}{47}\\approx 0.02rad  \\\\\n",
    "\\end{equation}\n",
    "\n",
    "- /!\\ Transformation in degree\n",
    "\\begin{equation}\n",
    "\\ Standard\\ Deviation\\ of\\ camera\\ tracking\\ measurement: \\sqrt{rp} = 1.34 deg\\\\\n",
    "\\ Standard\\ Deviation\\ of\\ camera\\ tracking\\ measurement: \\sqrt{rv} = 13.17 deg/s \\\\\n",
    "\\end{equation}\n",
    "\n",
    "_Q: The covariance of process noise_\n",
    "\n",
    "\n",
    "We estimate it by the last session exercise with Sysquake application. Using the Sysquake application, the speed variance in Thymio units is 197. Converted to mm2/s2, we obtain 197 · 0.33752 ≈ 22 mm2/s2. We assume half of it is caused by perturbations to the states, qv' = 11mm2/s2. The values of rp was taken arbitrarily by 0.04mm\n",
    "\n",
    "/!\\ Pay attention that we have now in rotation and in degree:\n",
    "\\begin{equation}\n",
    "\\dot{\\alpha}=\\frac{v}{R} \\\\\n",
    "\\end{equation}\n",
    "with R is the distance between one wheel and the center. R=47mm\n",
    "\n",
    "\n",
    "Then:\n",
    "\n",
    "\\\n",
    "\\begin{equation}\n",
    "\\ Standart\\ Deviation\\ on\\ position\\ state:  \\sqrt{q_p} = \\frac{\\sqrt{0.04}*{180}}{47*{\\pi}}=0.02 deg \\\\\n",
    "\\ Standart\\ Deviation\\ on\\ position\\ state : \\sqrt{q_v}= \\frac{\\sqrt{11}}{47}= 4.04 deg/s \\\\\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_rotation(angular, angular_dot): \n",
    "    \"\"\"Estimate the position and the speed in rotation with kalman filter when the robot moves\"\"\"\n",
    "    psi_observations = angular\n",
    "    psi_dot_observations = angular_dot\n",
    "\n",
    "    z = np.c_[psi_observations, psi_dot_observations]\n",
    "\n",
    "    # Initial Conditions\n",
    "\n",
    "    if (angular[0] < 0):\n",
    "        psi_dot = -200/2*0.3375/47*180/pi # 41.14 deg/s\n",
    "    elif (angular[0] > 0):\n",
    "        psi_dot = 200/2*0.3375/47*180/pi # 41.14 deg/s\n",
    "    else:\n",
    "        print(\"Error : First angle equals 0\")\n",
    "    \n",
    "    t = 0.5 # Difference in time\n",
    "\n",
    "    # Process / Estimation Errors\n",
    "    error_est_psi =  0.02      # sqrt(qp)\n",
    "    error_est_psi_dot =  4.04  # sqrt(qv)\n",
    "\n",
    "    # Observation Errors\n",
    "    error_obs_psi =   1.34     # sqrt(rp) Uncertainty in the measurement\n",
    "    error_obs_psi_dot = 13.17  # sqrt(rv)\n",
    "\n",
    "\n",
    "    # Initial Estimation Covariance Matrix\n",
    "    P = covariance2d(error_est_psi, error_est_psi_dot)\n",
    "    A = np.array([[1, t],\n",
    "                  [0, 1]])\n",
    "\n",
    "    # Initial State Matrix\n",
    "    X = np.array([[z[0][0]],\n",
    "                  [psi_dot]])\n",
    "    n = len(z[0])\n",
    "\n",
    "    for data in z[1:]:\n",
    "        X = prediction2d(X[0][0], X[1][0], t)\n",
    "        # set off-diagonal terms to 0.\n",
    "        P = np.diag(np.diag(A.dot(P).dot(A.T)))\n",
    "\n",
    "        # Calculating the Kalman Gain\n",
    "        H = np.identity(n)\n",
    "        R = covariance2d(error_obs_psi, error_obs_psi_dot)\n",
    "        S = H.dot(P).dot(H.T) + R # residual convariance #\n",
    "        K = P.dot(H).dot(inv(S))  # Kalman gain\n",
    "\n",
    "        # Reshape the new data into the measurement space.\n",
    "        Y = H.dot(data).reshape(n, -1)\n",
    "\n",
    "        # Update the State Matrix\n",
    "        # Combination of the predicted state, measured values, covariance matrix and Kalman Gain\n",
    "        X = X + K.dot(Y - H.dot(X))\n",
    "\n",
    "        # Update Process Covariance Matrix\n",
    "        P = (np.identity(len(K)) - K.dot(H)).dot(P)\n",
    "    \n",
    "    print(\"Kalman : \",X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def kalman_filling_rot(xb,yb,angles):\n",
    "    red_mean, blue_mean = get_red_blue()\n",
    "    xred = red_mean[0,0]*187/1280\n",
    "    yred = 140-red_mean[0,1]*140/960\n",
    "    xblue= blue_mean[0,0]*187/1280\n",
    "    yblue = 140-blue_mean[0,1]*140/960\n",
    "    u=[xb-xred,yb-yred]\n",
    "    v=[xblue-xred,yblue-yred]\n",
    "    angle=math.degrees(math.acos(np.dot(u,v)/(np.linalg.norm(u)*np.linalg.norm(v))))\n",
    "    if u[0]*v[1] - u[1]*v[0] < 0:\n",
    "        angle = -angle;    \n",
    "    angles = np.append(angles,angle)\n",
    "    print(\"Angle avec \",len(angles),\"éléments : \",angles)\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitation of our Kalman filter\n",
    "\n",
    "The actual implementation of the rotation of Kalman filter is redondant of the other tracking position. It would be not use in consideration for our programm. The consideration of the non-linearity of the Thymio can be one of the improvements.\n",
    "If we have more time, we could implement an Extended Kalman Filter for modeling the movement of a the Thymio with more states and to be more accurate.  An improvement could be to combine all 3 sensory inputs at our disposal: the ground sensors with some another patterns, the camera and the motor speeds. It could accurate all system more precisely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_observations : [ 3.9815005   7.85112165 11.59630574]\n",
      "v_observations : [7.963001   7.85112165 7.73087049]\n",
      "Kalman estimation:  [[11.53795486]\n",
      " [ 7.05323585]]\n",
      "x_observations : [3.58943373 7.25893499]\n",
      "v_observations : [7.17886745 7.25893499]\n",
      "Kalman estimation:  [[7.21150279]\n",
      " [6.83676137]]\n",
      "x_observations : [11.67182382 15.33503499 19.24178664]\n",
      "v_observations : [23.34364764 15.33503499 12.82785776]\n",
      "Kalman estimation:  [[19.26696377]\n",
      " [ 8.8856059 ]]\n",
      "x_observations : [ 2.40991381  6.22059785 10.10396392]\n",
      "v_observations : [4.81982763 6.22059785 6.73597595]\n",
      "Kalman estimation:  [[10.00173842]\n",
      " [ 6.67085162]]\n",
      "x_observations : [ 5.56211799  9.13128864 12.98061008 16.91382951 20.63221948 24.56913579\n",
      " 28.4801405 ]\n",
      "v_observations : [11.12423597  9.13128864  8.65374005  8.45691476  8.25288779  8.18971193\n",
      "  8.137183  ]\n",
      "Kalman estimation:  [[28.45372187]\n",
      " [ 7.69991764]]\n",
      "x_observations : [ 2.74960161  6.52569445 10.43275777 14.39346929]\n",
      "v_observations : [5.49920323 6.52569445 6.95517185 7.19673465]\n",
      "Kalman estimation:  [[14.26785202]\n",
      " [ 6.80436123]]\n",
      "x_observations : [3.54449059]\n",
      "v_observations : [7.08898119]\n",
      "Kalman estimation:  [[3.54449059]\n",
      " [6.75      ]]\n",
      "x_observations : [ 6.72640534 10.74162801]\n",
      "v_observations : [13.45281068 10.74162801]\n",
      "Kalman estimation:  [[10.63851412]\n",
      " [ 7.4304781 ]]\n",
      "x_observations : [ 4.12284471  8.13958541 12.04080638 16.15327946]\n",
      "v_observations : [8.24568943 8.13958541 8.02720425 8.07663973]\n",
      "Kalman estimation:  [[16.0387973 ]\n",
      " [ 7.25768771]]\n",
      "x_observations : [ 7.60885832 11.17914019 15.11590322 19.0709991 ]\n",
      "v_observations : [15.21771663 11.17914019 10.07726881  9.53549955]\n",
      "Kalman estimation:  [[19.06176088]\n",
      " [ 8.09020085]]\n",
      "x_observations : [ 2.14620207  6.14913823 10.1382166  14.12423134]\n",
      "v_observations : [4.29240414 6.14913823 6.75881107 7.06211567]\n",
      "Kalman estimation:  [[13.98186886]\n",
      " [ 6.71441165]]\n",
      "x_observations : [ 3.7453817   7.47852887 11.51450672]\n",
      "v_observations : [7.49076341 7.47852887 7.67633781]\n",
      "Kalman estimation:  [[11.40688852]\n",
      " [ 6.99102632]]\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "# Open the device at the ID 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "#Check whether user selected camera is opened successfully.\n",
    "if not (cap.isOpened()):\n",
    "    print(\"Could not open video device\")\n",
    "#To set the resolution\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 960)\n",
    "\n",
    "layout,blue_mean = vision()\n",
    "positionning(layout, blue_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Limitation of our system <a class=\"anchor\" id=\"6\"></a>\n",
    "\n",
    "**Map**\n",
    "- The \"official\" map starts at 5 cm from its borders\n",
    "\n",
    "**Placement of Start**\n",
    "- At the start of the demo, the Thymio should not be placed too close to a global obstacle (Like we calculate the edge of fixed obstacle + half of larger of Thymio). To be reasonable, it should be placed at least 5 centimeters away from the obstacle.\n",
    "\n",
    "**Placement of Goal**\n",
    "\n",
    "- It's the same as the Start (<5cm of obstacle) .\n",
    "\n",
    "**Placement of local obstacle** \n",
    "\n",
    "- Please place the local obstacle before the demo to avoid disturbing the camera when you put the obstacle on the map. The camera would detect and catch the coulour of your hand or your clothes.\n",
    "- The local obstacle should not be place less than 5 cm of the goal.\n",
    "\n",
    "**Robot wiring**\n",
    "\n",
    "- Since the latency of the Bluetooth system is too high, we had to connect the thymio with a 2-meter cable. With this fact, the cable should *NOT* intersect with the global obstacle at when the vision algorithm is running. Otherwise it could disturb the vision. It believes that there is another edge due to the wire.\n",
    "\n",
    "**Limitation in corner local/fixed obstacle**\n",
    "- When a local obstacle is placed near a corner of global obstacle to be reached, the Thymio will have to get around this local obstacle, but this will make the Thymio get away from its global trajectory ! So the Thymio will go backward to get at the same place as the local obstacle. So will will have to remove this obstacles before it goes backward.\n",
    "\n",
    "**postion of camera**\n",
    "- Pay attention to the setup of the camera. It should be place to 2.10 heights and the most horizontally to catch all the map.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-------------\n",
    "\n",
    "\n",
    "# Conclusion:\n",
    "\n",
    "All the objectives of the specifications have been achieved even though we encountered many problems. We worked in a good atmosphere and we had fun moving forward with the project. Each programming step can be immediately visible on the robot and it is very motivating. A great entry into the world of mobile of robotic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
